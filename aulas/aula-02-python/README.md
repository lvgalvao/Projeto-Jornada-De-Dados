# ğŸ Dia 2: Python & IngestÃ£o de Dados | Jornada de Dados

Bem-vindo ao **segundo dia da imersÃ£o Jornada de Dados**! Hoje vocÃª vai aprender Python para trabalhar com dados, focando em **ingestÃ£o** - o processo de coletar dados de diferentes fontes e preparÃ¡-los para anÃ¡lise.

---

## ğŸ“– O que Ã© Python para Dados?

**Python** Ã© uma linguagem de programaÃ§Ã£o versÃ¡til e poderosa que se tornou o padrÃ£o da indÃºstria para trabalhar com dados. Ã‰ a ferramenta que permite:

- âœ… **Ingerir dados** - Coletar dados de APIs, arquivos externos, bancos de dados, Data Lakes
- âœ… **Processar dados** - Limpar, transformar e preparar dados para anÃ¡lise
- âœ… **Analisar dados** - Fazer anÃ¡lises estatÃ­sticas e exploratÃ³rias
- âœ… **Automatizar tarefas** - Criar scripts que fazem o trabalho pesado

**Python nÃ£o Ã© apenas uma linguagem de programaÃ§Ã£o.** Ã‰ um ecossistema completo com bibliotecas especializadas para cada necessidade de dados.

---

## ğŸ”„ Processo de IngestÃ£o de Dados

**Ontem (Dia 1 - SQL):** Trabalhamos com dados que **jÃ¡ existiam** no banco de dados (4 tabelas: produtos, clientes, vendas, preco_competidores).

**Hoje (Dia 2 - Python):** Vamos **trazer novos dados** para o banco atravÃ©s do Python, coletando dados de diferentes fontes externas.

### ğŸ“Š Fluxo de IngestÃ£o de Dados

O diagrama abaixo mostra como Python atua como **ponte** entre diferentes fontes de dados e o banco SQL:

```mermaid
graph TB
    subgraph "ğŸŒ Fontes de Dados Externas"
        API[ğŸ“¡ APIs REST<br/>Bitcoin, NASA, etc]
        ARQ[ğŸ“ Arquivos Externos<br/>GitHub, S3, URLs]
        BANCO[ğŸ—„ï¸ Outros Bancos<br/>PostgreSQL, MySQL]
        LAKE[ğŸ’¾ Data Lakes<br/>S3, Azure, GCS]
        SISTEMA[âš™ï¸ Sistemas<br/>ERP, CRM, etc]
    end
    
    subgraph "ğŸ Python - IngestÃ£o"
        EXTRAIR[ğŸ“¥ Extrair Dados]
        TRANSFORMAR[ğŸ”„ Transformar/Limpar]
        VALIDAR[âœ… Validar Dados]
    end
    
    subgraph "ğŸ—„ï¸ Banco de Dados SQL"
        PRODUTOS[(ğŸ“¦ produtos)]
        CLIENTES[(ğŸ‘¥ clientes)]
        VENDAS[(ğŸ’° vendas)]
        CONCORRENTES[(ğŸª preco_competidores)]
        NOVOS_DADOS[(ğŸ†• novos_dados)]
    end
    
    API -->|requests.get| EXTRAIR
    ARQ -->|requests + pandas| EXTRAIR
    BANCO -->|sqlalchemy| EXTRAIR
    LAKE -->|boto3/pyarrow| EXTRAIR
    SISTEMA -->|API/arquivos| EXTRAIR
    
    EXTRAIR --> TRANSFORMAR
    TRANSFORMAR --> VALIDAR
    VALIDAR -->|pandas.to_sql| PRODUTOS
    VALIDAR -->|pandas.to_sql| CLIENTES
    VALIDAR -->|pandas.to_sql| VENDAS
    VALIDAR -->|pandas.to_sql| CONCORRENTES
    VALIDAR -->|pandas.to_sql| NOVOS_DADOS
    
    style API fill:#4A90E2,color:#fff
    style ARQ fill:#FF6B6B,color:#fff
    style BANCO fill:#FFA500,color:#fff
    style LAKE fill:#9B59B6,color:#fff
    style SISTEMA fill:#1ABC9C,color:#fff
    style EXTRAIR fill:#E74C3C,color:#fff
    style TRANSFORMAR fill:#F39C12,color:#fff
    style VALIDAR fill:#27AE60,color:#fff
    style PRODUTOS fill:#3498DB,color:#fff
    style CLIENTES fill:#3498DB,color:#fff
    style VENDAS fill:#3498DB,color:#fff
    style CONCORRENTES fill:#3498DB,color:#fff
    style NOVOS_DADOS fill:#2ECC71,color:#fff
```

### ğŸ¯ Exemplo PrÃ¡tico: IntegraÃ§Ã£o de Dados Externos

**Caso de NegÃ³cio:** Coletar dados de produtos e preÃ§os de arquivos pÃºblicos (GitHub, S3) para anÃ¡lise competitiva.

**Fluxo:**
1. ğŸ“ **Arquivos Externos** â†’ Python baixa dados de repositÃ³rios pÃºblicos (Parquet, CSV)
2. ğŸ”„ **TransformaÃ§Ã£o** â†’ Limpa e padroniza dados
3. âœ… **ValidaÃ§Ã£o** â†’ Verifica qualidade dos dados
4. ğŸ—„ï¸ **Carga** â†’ Salva na tabela `preco_competidores` do banco SQL
5. ğŸ“Š **AnÃ¡lise** â†’ SQL compara nossos preÃ§os com concorrentes

**Resultado:** Dados atualizados de concorrentes prontos para anÃ¡lise no banco SQL!

### ğŸ“š Principais Bibliotecas Python para Dados

| Biblioteca | Logo | DescriÃ§Ã£o | GitHub |
|------------|------|-----------|--------|
| **Pandas** | ğŸ¼ | ManipulaÃ§Ã£o e anÃ¡lise de dados tabulares | [pandas-dev/pandas](https://github.com/pandas-dev/pandas) |
| **PySpark** | âš¡ | Processamento distribuÃ­do de Big Data | [apache/spark](https://github.com/apache/spark) |
| **Airflow** | âœˆï¸ | OrquestraÃ§Ã£o e agendamento de pipelines | [apache/airflow](https://github.com/apache/airflow) |
| **Streamlit** | ğŸˆ | CriaÃ§Ã£o rÃ¡pida de dashboards e apps web | [streamlit/streamlit](https://github.com/streamlit/streamlit) |
| **NumPy** | ğŸ”¢ | ComputaÃ§Ã£o numÃ©rica e arrays multidimensionais | [numpy/numpy](https://github.com/numpy/numpy) |
| **Scikit-learn** | ğŸ¤– | Machine Learning e anÃ¡lise de dados | [scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn) |
| **Matplotlib** | ğŸ“Š | VisualizaÃ§Ã£o de dados e grÃ¡ficos | [matplotlib/matplotlib](https://github.com/matplotlib/matplotlib) |
| **Requests** | ğŸŒ | RequisiÃ§Ãµes HTTP e consumo de APIs | [psf/requests](https://github.com/psf/requests) |
| **PyArrow** | ğŸ¹ | Leitura/escrita de Parquet e formatos colunares | [apache/arrow](https://github.com/apache/arrow) |
| **SQLAlchemy** | ğŸ—„ï¸ | ORM e acesso a bancos de dados | [sqlalchemy/sqlalchemy](https://github.com/sqlalchemy/sqlalchemy) |

**Cada biblioteca resolve um problema especÃ­fico:**
- ğŸ¼ **Pandas**: Trabalhar com dados tabulares (CSV, Excel, SQL)
- âš¡ **PySpark**: Processar grandes volumes de dados distribuÃ­dos
- âœˆï¸ **Airflow**: Orquestrar e agendar pipelines de dados
- ğŸˆ **Streamlit**: Criar dashboards interativos rapidamente
- ğŸ”¢ **NumPy**: OperaÃ§Ãµes matemÃ¡ticas e arrays eficientes
- ğŸ¤– **Scikit-learn**: Machine Learning e modelos preditivos
- ğŸ“Š **Matplotlib**: Visualizar dados com grÃ¡ficos
- ğŸŒ **Requests**: Consumir APIs e fazer requisiÃ§Ãµes HTTP
- ğŸ¹ **PyArrow**: Trabalhar com arquivos Parquet (formato otimizado para Big Data)
- ğŸ—„ï¸ **SQLAlchemy**: Conectar e trabalhar com bancos de dados

**Exemplo:**
```python
# VocÃª diz: "Quero ler dados de vendas e calcular receita total"
import pandas as pd

df = pd.read_csv("vendas.csv")
df['receita'] = df['quantidade'] * df['preco_unitario']
receita_total = df['receita'].sum()

print(f"Receita total: R$ {receita_total:,.2f}")
```

---

## ğŸ’¼ Mercado de Python para Dados

Python Ã© a linguagem mais usada no mercado de dados e ciÃªncia de dados:

### ğŸ“Š Por que Python Ã© importante?

1. **Ecossistema rico**: Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch
2. **Demanda de mercado**: Habilidade essencial em 90% das vagas de dados
3. **Versatilidade**: Serve para anÃ¡lise, engenharia, machine learning, automaÃ§Ã£o
4. **Comunidade**: Grande comunidade, muitos recursos e bibliotecas open-source
5. **IntegraÃ§Ã£o**: FÃ¡cil integraÃ§Ã£o com bancos de dados, APIs, sistemas

### ğŸ¯ Onde Python Ã© usado?

- **Data Engineering**: Pipelines de dados, ETL, ingestÃ£o
- **Data Analysis**: AnÃ¡lise exploratÃ³ria, relatÃ³rios automatizados
- **Data Science**: Machine Learning, estatÃ­stica, modelagem
- **AutomaÃ§Ã£o**: Scripts para tarefas repetitivas
- **APIs e IntegraÃ§Ãµes**: Conectar diferentes sistemas

### ğŸ’° SalÃ¡rios no Brasil (2024)

- **Analista de Dados JÃºnior**: R$ 3.000 - R$ 6.000
- **Analista de Dados Pleno**: R$ 6.000 - R$ 10.000
- **Analista de Dados SÃªnior**: R$ 10.000 - R$ 18.000
- **Cientista de Dados**: R$ 8.000 - R$ 20.000+
- **Engenheiro de Dados**: R$ 10.000 - R$ 25.000+

**Python Ã© a base de todas essas carreiras.**

**Pesquisa de Vagas:**
- ğŸ” [LinkedIn: Python & SQL no Brasil](https://www.linkedin.com/jobs/search/?currentJobId=4350781561&geoId=106057199&keywords=python%20%26%20sql&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true) - **13.000+ vagas disponÃ­veis**

**Fonte:** Glassdoor, LinkedIn, pesquisas de mercado 2024

---

## ğŸ¯ Foco do Curso

Neste **Dia 2**, vamos focar em:

âœ… **IngestÃ£o de Dados** - 70% do tempo  
âœ… **Tratamento BÃ¡sico** - 20% do tempo  
âœ… **ExportaÃ§Ã£o** - 10% do tempo  

**Por quÃª?** Engenheiros e analistas de dados passam a maior parte do tempo coletando e preparando dados. VocÃª vai aprender a **pensar como engenheiro de dados** e **integrar diferentes fontes de dados**.

---

## ğŸ”„ SQL vs Python: Qual a DiferenÃ§a?

### ğŸ“Š SQL (Dia 1)
**Trabalha com dados que JÃ EXISTEM no banco de dados**

- âœ… Dados jÃ¡ estÃ£o armazenados
- âœ… Foco em consultar e analisar
- âœ… Linguagem declarativa (diz o que quer)
- âœ… Otimizado para grandes volumes
- âœ… Ideal para anÃ¡lises e relatÃ³rios

**Exemplo:**
```sql
-- Os dados JÃ ESTÃƒO no banco
SELECT * FROM vendas WHERE data_venda > '2024-01-01';
```

### ğŸ Python (Dia 2)
**BUSCA dados de sistemas externos e integra diferentes fontes**

- âœ… Dados vÃªm de sistemas externos (APIs, arquivos externos, Data Lakes)
- âœ… Foco em coletar e integrar
- âœ… Linguagem imperativa (diz como fazer)
- âœ… Ideal para automaÃ§Ã£o e integraÃ§Ã£o
- âœ… Conecta diferentes sistemas

**Exemplo:**
```python
# BUSCA dados de uma API externa
import requests
dados = requests.get("https://api.coinbase.com/v2/prices/spot").json()
```

### ğŸ¯ Resumo

| Aspecto | SQL | Python |
|---------|-----|--------|
| **Dados** | JÃ¡ existem no banco | Busca de sistemas externos |
| **Foco** | Consultar e analisar | Coletar e integrar |
| **Uso** | AnÃ¡lises e relatÃ³rios | APIs, scraping, automaÃ§Ã£o |
| **Quando usar** | Dados jÃ¡ armazenados | Dados externos, integraÃ§Ã£o |

**Python na engenharia de dados = COMUNICAR e INTEGRAR sistemas externos!**

---

## ğŸ¯ Perguntas de NegÃ³cio que Vamos Responder

Este **Dia 2** foi criado para resolver problemas reais de ingestÃ£o de dados. Abaixo estÃ£o todas as perguntas que vamos responder com os exemplos:

### ğŸ”¥ Aquecimento (Fundamentos)

1. **Por que preciso saber Python bÃ¡sico para trabalhar com dados?** *(Exemplo 00)*
2. **O que Ã© uma API e como processar dados JSON?** *(Exemplo 00b)*
3. **Por que usar Pandas ao invÃ©s de listas/dicionÃ¡rios?** *(Exemplo 00c)*

### ğŸ“‚ IngestÃ£o de Dados (Exemplos 1-7)

4. **Como carregar dados de CSVs em Python?** *(Exemplo 1)*
5. **Como combinar dados de mÃºltiplos arquivos?** *(Exemplo 2)*
6. **Como buscar dados de uma API REST?** *(Exemplo 3)*
7. **Como ler arquivos de fontes externas (GitHub, S3, Data Lakes)?** *(Exemplo 4)*
8. **Como ler dados diretamente de um banco de dados?** *(Exemplo 5)*
9. **Como limpar e tratar dados inconsistentes?** *(Exemplo 6)*
10. **Como exportar dados processados para diferentes formatos?** *(Exemplo 7)*

---

## ğŸ”¥ Bloco 1: Aquecimento Python (20min)

Antes de trabalhar com dados, Ã© essencial dominar os fundamentos de Python. Este bloco garante que vocÃª tenha a base necessÃ¡ria.

#### `exemplo-00-aquecimento-fundamentos.py`
**Conceito:** Fundamentos de Python  
**Pergunta de NegÃ³cio:** Por que preciso saber Python bÃ¡sico para trabalhar com dados?  
**O que vocÃª aprende:**
- Print e Hello World
- VariÃ¡veis e tipos bÃ¡sicos (str, int, float)
- Estruturas de dados (lista, dicionÃ¡rio)
- MÃ©todos Ãºteis
- Por que isso Ã© importante para trabalhar com dados

**Conceitos Python:**
- `print()`: exibir informaÃ§Ãµes
- VariÃ¡veis: `str`, `int`, `float`
- Listas: `[]` - coleÃ§Ã£o ordenada
- DicionÃ¡rios: `{}` - pares chave-valor
- MÃ©todos: funÃ§Ãµes dos objetos (`.upper()`, `.strip()`, etc.)

**Por que Ã© importante?**
- APIs retornam dados em JSON (que sÃ£o dicionÃ¡rios em Python)
- Arquivos externos precisam ser baixados e processados
- Dados de CSVs sÃ£o lidos como strings e precisam conversÃ£o
- Pandas usa esses conceitos por baixo dos panos

---

#### `exemplo-00c-introducao-pandas.py`
**Conceito:** IntroduÃ§Ã£o ao Pandas  
**Pergunta de NegÃ³cio:** Por que Pandas Ã© a biblioteca mais usada para dados em Python?  
**O que vocÃª aprende:**
- O que Ã© Pandas
- Por que usar Pandas ao invÃ©s de listas/dicionÃ¡rios
- Conceitos bÃ¡sicos: Series e DataFrame
- OperaÃ§Ãµes bÃ¡sicas com Pandas
- Por que Pandas Ã© essencial para trabalhar com dados

**Conceitos Python:**
- `pd.Series`: uma coluna de dados
- `pd.DataFrame`: tabela de dados
- OperaÃ§Ãµes: filtros, agregaÃ§Ãµes, cÃ¡lculos
- `df.groupby()`: agrupar dados
- `df.describe()`: estatÃ­sticas descritivas

**Vantagens do Pandas:**
- OperaÃ§Ãµes diretas (sem loops)
- CÃ³digo limpo e legÃ­vel
- Otimizado para performance
- Funcionalidades prontas (filtros, agregaÃ§Ãµes, joins)
- IntegraÃ§Ã£o com Excel, SQL, APIs

---

## ğŸ¯ ProgressÃ£o de Aprendizado

A aula estÃ¡ dividida em **4 blocos de 20 minutos cada**, totalizando 80 minutos de aprendizado prÃ¡tico:

1. **ğŸ”¥ Aquecimento Python (20min)** - Fundamentos essenciais
2. **ğŸ’¾ Conectar com DataLake (20min)** - Trabalhar com armazenamento em nuvem
3. **ğŸ—„ï¸ Salvar no Banco de Dados (20min)** - Persistir dados processados
4. **ğŸŒ Conectar com uma API (20min)** - Integrar dados externos

---

### ğŸ”¥ Bloco 1: Aquecimento Python (20min)

Antes de trabalhar com dados, Ã© essencial dominar os fundamentos de Python. Este bloco garante que vocÃª tenha a base necessÃ¡ria.

---

### ğŸ’¾ Bloco 2: Conectar com DataLake (20min)

Data Lakes sÃ£o repositÃ³rios centralizados para armazenar grandes volumes de dados. Aprenda a conectar e ler dados de Data Lakes usando a API S3 (padrÃ£o da indÃºstria).

#### `exemplo-00b-api-json.py`
**Conceito:** Fundamentos de APIs e JSON  
**Pergunta de NegÃ³cio:** O que Ã© uma API e como processar dados JSON em Python?  
**O que vocÃª aprende:**
- O que Ã© uma API (Application Programming Interface)
- O que Ã© JSON e como funciona
- Como JSON se relaciona com dicionÃ¡rios Python
- Como processar dados de APIs
- Por que isso Ã© essencial para ingestÃ£o de dados

**Conceitos Python:**
- `json.loads()`: converte JSON string para dicionÃ¡rio Python
- `json.dumps()`: converte dicionÃ¡rio Python para JSON string
- Acessar dados aninhados: `dados["chave"]["subchave"]`
- Processar listas de dicionÃ¡rios

**Por que APIs sÃ£o importantes?**
- Python na engenharia de dados = COMUNICAR com sistemas externos
- SQL trabalha com dados que JÃ EXISTEM no banco
- Python BUSCA dados de sistemas externos via APIs
- Permite integrar dados de mÃºltiplas fontes

**Casos de uso:**
- Consumir APIs REST
- Processar respostas de APIs
- Converter entre formatos
- Trabalhar com dados estruturados

**Resultado Esperado:**
- CompreensÃ£o do que Ã© API e JSON
- Capacidade de processar dados JSON em Python
- Entendimento de como APIs funcionam

---

#### `exemplo-03-ler-api-rest.py`
**Conceito:** Consumir APIs REST na prÃ¡tica  
**Pergunta de NegÃ³cio:** Como obter dados de uma API externa em Python?  
**O que vocÃª aprende:**
- Como fazer requisiÃ§Ãµes HTTP com requests
- Como consumir APIs REST
- Como tratar respostas JSON
- Como trabalhar com diferentes tipos de dados (JSON, imagens)
- Exemplos prÃ¡ticos: Bitcoin e NASA

**Conceitos Python:**
- `requests.get()`: faz requisiÃ§Ã£o HTTP GET
- `response.json()`: converte resposta para dicionÃ¡rio Python
- `response.raise_for_status()`: verifica erros HTTP
- Tratamento de exceÃ§Ãµes com try/except

**Exemplos prÃ¡ticos:**
- **API Bitcoin (Coinbase)**: preÃ§os de criptomoedas em tempo real
- **API NASA**: imagens e dados espaciais

**Resultado Esperado:**
- Dados obtidos de API Bitcoin com sucesso
- Dados obtidos de API NASA com sucesso
- Respostas JSON convertidas para DataFrame
- Tratamento de erros implementado

---

#### `exemplo-04-ler-arquivos-externos.py`
**Conceito:** Conectar com DataLake (S3/Supabase Storage)  
**Pergunta de NegÃ³cio:** Como ler dados de um Data Lake usando a API S3?  
**O que vocÃª aprende:**
- O que Ã© um Data Lake e por que Ã© importante
- Como usar boto3 para conectar com S3/Supabase Storage
- Como ler arquivos CSV e Parquet de Data Lakes
- Por que AWS S3 Ã© o padrÃ£o da indÃºstria (mais de 50% das empresas usam)
- Como trabalhar com armazenamento em nuvem

**Conceitos Python:**
- `boto3.client()`: cria cliente S3 (compatÃ­vel com Supabase Storage)
- `s3.get_object()`: baixa arquivo do Data Lake
- `pd.read_csv(io.BytesIO())`: lÃª CSV da memÃ³ria
- `pd.read_parquet(io.BytesIO())`: lÃª Parquet da memÃ³ria

**Por que Data Lakes sÃ£o importantes?**
- Armazenam grandes volumes de dados (terabytes/petabytes)
- MantÃªm dados em formato original (sem transformaÃ§Ã£o prÃ©via)
- Suportam mÃºltiplos formatos (CSV, Parquet, JSON)
- Escalabilidade horizontal (cresce conforme necessidade)
- Economia de custos (armazenamento barato)

**AWS S3 Ã© o padrÃ£o da indÃºstria:**
- Mais de 50% das empresas usam AWS S3 para Data Lakes
- API padrÃ£o que funciona com mÃºltiplas ferramentas
- CompatÃ­vel com Supabase Storage, MinIO, e outros

**Resultado Esperado:**
- ConexÃ£o estabelecida com Data Lake
- Arquivo CSV baixado e carregado com sucesso
- Dados analisados (concorrentes, estatÃ­sticas de preÃ§os)
- CompreensÃ£o da importÃ¢ncia de Data Lakes na indÃºstria

---

### ğŸ—„ï¸ Bloco 3: Salvar no Banco de Dados (20min)

ApÃ³s processar dados, Ã© essencial salvÃ¡-los em um banco de dados para consultas e anÃ¡lises. Aprenda a conectar Python com bancos SQL e persistir dados processados.

#### `exemplo-05-ler-banco-dados.py`
**Conceito:** Conectar Python com bancos de dados SQL  
**Pergunta de NegÃ³cio:** Como ler dados diretamente de um banco SQL em Python?  
**O que vocÃª aprende:**
- Como conectar Python com SQLite
- Como conectar Python com PostgreSQL
- Como executar queries SQL e trazer para pandas
- Como trabalhar com diferentes tipos de banco

**Conceitos Python:**
- `sqlite3.connect()`: conecta com SQLite
- `pd.read_sql_query()`: executa SQL e retorna DataFrame
- `sqlalchemy.create_engine()`: cria engine para PostgreSQL
- `df.to_sql()`: salva DataFrame em tabela SQL

**Vantagens:**
- Dados sempre atualizados (nÃ£o precisa exportar CSV)
- Queries complexas diretamente no banco
- Performance melhor para grandes volumes
- IntegraÃ§Ã£o nativa com SQL

**Resultado Esperado:**
- ConexÃ£o com banco estabelecida
- Queries SQL executadas com sucesso
- Dados retornados como DataFrame

---

#### `exemplo-07-exportar-dados.py`
**Conceito:** Salvar dados processados no banco de dados  
**Pergunta de NegÃ³cio:** Como salvar dados processados em um banco SQL?  
**O que vocÃª aprende:**
- Como exportar DataFrame para banco de dados SQL
- Como usar `df.to_sql()` para persistir dados
- Como escolher o formato adequado (CSV, JSON, Excel, SQL)
- Como trabalhar com diferentes tipos de banco

**Conceitos Python:**
- `df.to_sql()`: exporta DataFrame para tabela SQL
- `df.to_csv()`: exporta para CSV
- `df.to_json()`: exporta para JSON
- `df.to_excel()`: exporta para Excel
- `df.to_parquet()`: exporta para Parquet (otimizado)

**Quando usar cada formato:**
- **SQL**: Dados que precisam ser consultados frequentemente
- **CSV**: Universal, fÃ¡cil de abrir em Excel
- **JSON**: Ideal para APIs e integraÃ§Ãµes
- **Excel**: Bom para relatÃ³rios e apresentaÃ§Ãµes
- **Parquet**: Otimizado para big data, compressÃ£o eficiente

**Resultado Esperado:**
- Dados exportados para banco de dados com sucesso
- Dados prontos para consultas SQL
- Formato escolhido baseado no uso

---

### ğŸŒ Bloco 4: Conectar com uma API (20min)

APIs sÃ£o a forma padrÃ£o de comunicaÃ§Ã£o entre sistemas. Aprenda a consumir APIs REST e processar dados JSON em Python.

---

## ğŸ“š Exemplos Adicionais (Opcionais)

Estes exemplos complementam o aprendizado e podem ser explorados apÃ³s os 4 blocos principais:

### `exemplo-01-ler-csv.py` e `exemplo-02-ler-multiplos-csv.py`
**Conceito:** Trabalhar com arquivos CSV locais  
**Quando usar:** Quando vocÃª tem arquivos CSV no seu computador e precisa carregÃ¡-los.

### `exemplo-06-tratar-dados.py`
**Conceito:** Limpar e preparar dados para anÃ¡lise  
**Quando usar:** Quando precisa tratar dados inconsistentes, faltantes ou duplicados antes de salvar no banco.

---

## ğŸ“ Como Usar

### 1. Instalar DependÃªncias

```bash
# Criar ambiente virtual (recomendado)
python -m venv venv

# Ativar ambiente virtual
# No Windows:
venv\Scripts\activate
# No Mac/Linux:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Executar Exemplos

```bash
# Navegar para diretÃ³rio de exemplos
cd aulas/aula-02-python/exemplos

# ğŸ”¥ BLOCO 1: Aquecimento Python (20min)
python exemplo-00-aquecimento-fundamentos.py
python exemplo-00c-introducao-pandas.py

# ğŸ’¾ BLOCO 2: Conectar com DataLake (20min)
python exemplo-04-ler-arquivos-externos.py

# ğŸ—„ï¸ BLOCO 3: Salvar no Banco de Dados (20min)
python exemplo-05-ler-banco-dados.py
python exemplo-07-exportar-dados.py

# ğŸŒ BLOCO 4: Conectar com uma API (20min)
python exemplo-00b-api-json.py
python exemplo-03-ler-api-rest.py
```

### 3. Modificar e Experimentar

- Altere os caminhos dos arquivos
- Teste com seus prÃ³prios dados
- Combine conceitos de diferentes exemplos
- Crie seus prÃ³prios scripts

---

## ğŸ“ Checklist de Aprendizado

ApÃ³s fazer todos os exemplos, vocÃª deve ser capaz de:

### ğŸ”¥ Bloco 1: Aquecimento Python
- [ ] Usar print e f-strings
- [ ] Trabalhar com variÃ¡veis (str, int, float)
- [ ] Usar listas e dicionÃ¡rios
- [ ] Entender o que Ã© Pandas e por que usar
- [ ] Criar Series e DataFrames
- [ ] Fazer operaÃ§Ãµes bÃ¡sicas com Pandas

### ğŸ’¾ Bloco 2: Conectar com DataLake
- [ ] Entender o que Ã© um Data Lake
- [ ] Usar boto3 para conectar com S3/Supabase Storage
- [ ] Baixar arquivos de Data Lakes
- [ ] Ler arquivos CSV e Parquet de Data Lakes
- [ ] Compreender a importÃ¢ncia de Data Lakes na indÃºstria

### ğŸ—„ï¸ Bloco 3: Salvar no Banco de Dados
- [ ] Conectar Python com SQLite e PostgreSQL
- [ ] Executar queries SQL e trazer para pandas
- [ ] Salvar DataFrames em tabelas SQL
- [ ] Exportar dados para diferentes formatos (CSV, JSON, Excel, Parquet)

### ğŸŒ Bloco 4: Conectar com uma API
- [ ] Entender o que Ã© API e JSON
- [ ] Converter entre JSON e dicionÃ¡rios Python
- [ ] Fazer requisiÃ§Ãµes HTTP para APIs
- [ ] Processar respostas de APIs
- [ ] Integrar dados de mÃºltiplas APIs

---

## ğŸ’¡ Dicas

- **Execute em ordem:** Cada exemplo introduz um conceito novo
- **Modifique:** Tente adaptar os scripts para seus prÃ³prios dados
- **Combine:** Use conceitos de exemplos anteriores em novos contextos
- **Valide:** Sempre verifique se os dados foram carregados corretamente
- **Pratique:** Crie seus prÃ³prios scripts de ingestÃ£o

---

## ğŸ› Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'pandas'"
```bash
pip install pandas
```

### Erro: "FileNotFoundError: vendas.csv"
- Verifique se os arquivos CSV estÃ£o na pasta `data/`
- Verifique o caminho relativo no script

### Erro: "ConnectionError" ao baixar arquivos externos
- Verifique sua conexÃ£o com internet
- Verifique se a URL do arquivo estÃ¡ correta e acessÃ­vel
- Alguns repositÃ³rios podem ter rate limiting - adicione delays entre requisiÃ§Ãµes

### Erro: "sqlite3.OperationalError: no such table"
- Execute primeiro o exemplo que cria o banco
- Verifique se o banco foi criado corretamente

---

## ğŸ¯ PrÃ³ximos Passos

Depois de dominar todos os exemplos:

1. Pratique criando seus prÃ³prios scripts de ingestÃ£o
2. Combine diferentes fontes de dados
3. Automatize processos de coleta de dados
4. Avance para a **Aula 3: Engenharia de Dados**

---

## ğŸ“Š Resumo dos Conceitos por Exemplo

| Bloco | Exemplo | Conceito Principal | Tempo |
|-------|---------|-------------------|-------|
| ğŸ”¥ 1 | 00 | Fundamentos Python | 10min |
| ğŸ”¥ 1 | 00c | IntroduÃ§Ã£o Pandas | 10min |
| ğŸ’¾ 2 | 04 | DataLake (S3/Supabase) | 20min |
| ğŸ—„ï¸ 3 | 05 | Banco de Dados | 10min |
| ğŸ—„ï¸ 3 | 07 | Exportar Dados | 10min |
| ğŸŒ 4 | 00b | APIs e JSON | 10min |
| ğŸŒ 4 | 03 | API REST | 10min |

**Total: 4 blocos de 20 minutos cada = 80 minutos de aprendizado prÃ¡tico!** ğŸš€

---

## ğŸ”— Recursos Adicionais

- [DocumentaÃ§Ã£o Pandas](https://pandas.pydata.org/docs/)
- [DocumentaÃ§Ã£o Requests](https://requests.readthedocs.io/)
- [DocumentaÃ§Ã£o PyArrow (Parquet)](https://arrow.apache.org/docs/python/)
- [SQLAlchemy Tutorial](https://docs.sqlalchemy.org/en/20/tutorial/)

---

**Boa jornada! ğŸ**

